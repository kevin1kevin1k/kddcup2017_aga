{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "from src import functions as func\n",
    "from src import feagen as feag\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense,GRU,Activation\n",
    "from keras.layers.core import Flatten,Dropout\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "%matplotlib inline\n",
    "\n",
    "task = 'am'\n",
    "target = 'A-3'\n",
    "\n",
    "if task == 'am':\n",
    "    window_start = datetime.strptime('2016-10-18 08:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "elif task == 'pm':\n",
    "    window_start = datetime.strptime('2016-10-18 17:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "else:\n",
    "    sys.exit(\"Usage : Only am or pm for <task>\")\n",
    "    \n",
    "windows = []\n",
    "for d in range(7):\n",
    "    for t in range(6):\n",
    "        windows.append('\\\"['+str(window_start +timedelta(minutes=20*t))+','+ str(window_start +timedelta(minutes=20*(t+1)))+')\\\"')\n",
    "    window_start  += timedelta(days=1)\n",
    "\n",
    "def create_dataset(dataset,lookback = 1):\n",
    "    dataX,dataY = [],[]\n",
    "    for day in dataset:\n",
    "        for i in range(len(day)-look_back):\n",
    "            a = day[i:(i+look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append([day[i + look_back, 0]])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def my_mape(label,pred):\n",
    "    c = 0.0\n",
    "    mae = 0.0\n",
    "    for (l,p) in zip(label.flatten(),pred.flatten()):\n",
    "        if l != 0:\n",
    "            mae += abs(l-p)/l\n",
    "            c += 1\n",
    "    return mae/c,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-3', 'B-1', 'A-3', 'A-2', 'C-3', 'C-1']\n",
      "2016-10-18 06:00:00 [78.4, 104.14, 25.9]\n",
      "2016-10-18 06:20:00 [100.92, 183.1]\n",
      "2016-10-18 06:40:00 [549.98, 169.37, 212.71, 172.41, 121.7, 175.91]\n",
      "2016-10-18 07:00:00 [120.02, 116.48, 197.91, 140.18]\n",
      "2016-10-18 07:20:00 [125.99000000000001, 143.54, 56.08, 118.43, 152.69, 153.87, 242.24, 219.23]\n",
      "2016-10-18 07:40:00 [175.8, 221.99, 201.78, 217.81, 221.5, 180.24, 216.92000000000002, 225.64]\n",
      "2016-10-18 08:00:00  None\n",
      "2016-10-18 08:20:00  None\n",
      "2016-10-18 08:40:00  None\n",
      "2016-10-18 09:00:00  None\n",
      "2016-10-18 09:20:00  None\n",
      "2016-10-18 09:40:00  None\n",
      "2016-10-19 06:00:00 [113.62, 65.4]\n",
      "2016-10-19 06:20:00 [197.56, 187.63, 107.96000000000001, 153.39]\n",
      "2016-10-19 06:40:00 [205.84, 81.53999999999999, 138.78, 107.57]\n",
      "2016-10-19 07:00:00 [108.24, 102.68, 181.98, 177.0, 120.84, 148.57]\n",
      "2016-10-19 07:20:00 [206.35, 138.17000000000002, 191.75, 168.46, 160.15, 165.73]\n",
      "2016-10-19 07:40:00 [153.78, 228.87, 229.65, 120.56, 140.03, 276.43, 209.61, 297.69, 264.58, 191.56, 221.24, 259.79]\n",
      "2016-10-19 08:00:00  None\n",
      "2016-10-19 08:20:00  None\n",
      "2016-10-19 08:40:00  None\n",
      "2016-10-19 09:00:00  None\n",
      "2016-10-19 09:20:00  None\n",
      "2016-10-19 09:40:00  None\n",
      "2016-10-20 06:00:00 [72.17, 133.73, 133.25]\n",
      "2016-10-20 06:20:00 [106.91, 87.9, 80.61, 111.56, 121.37]\n",
      "2016-10-20 06:40:00 [159.14, 190.81, 163.72, 150.04, 264.67, 203.35, 276.68]\n",
      "2016-10-20 07:00:00 [200.44, 183.86, 142.25, 147.01, 130.62]\n",
      "2016-10-20 07:20:00 [119.69, 110.65, 110.66, 97.55, 151.03, 101.76, 188.79, 96.4, 135.61, 199.64, 198.55, 103.09, 173.32, 228.34]\n",
      "2016-10-20 07:40:00 [221.32, 206.54, 181.4]\n",
      "2016-10-20 08:00:00  None\n",
      "2016-10-20 08:20:00  None\n",
      "2016-10-20 08:40:00  None\n",
      "2016-10-20 09:00:00  None\n",
      "2016-10-20 09:20:00  None\n",
      "2016-10-20 09:40:00  None\n",
      "2016-10-21 06:00:00 [112.16]\n",
      "2016-10-21 06:20:00 [98.66, 112.97999999999999, 84.32, 129.31, 137.71]\n",
      "2016-10-21 06:40:00 [104.65, 116.78999999999999, 135.76, 209.03]\n",
      "2016-10-21 07:00:00 [161.91, 77.37, 139.29, 107.73, 98.58, 143.41, 139.71, 83.86]\n",
      "2016-10-21 07:20:00 [196.62, 139.44, 210.21, 156.74, 164.42000000000002, 308.63, 162.29]\n",
      "2016-10-21 07:40:00 [147.65, 175.5, 208.67000000000002, 157.42000000000002, 130.0, 159.05, 155.01, 197.48, 120.67]\n",
      "2016-10-21 08:00:00  None\n",
      "2016-10-21 08:20:00  None\n",
      "2016-10-21 08:40:00  None\n",
      "2016-10-21 09:00:00  None\n",
      "2016-10-21 09:20:00  None\n",
      "2016-10-21 09:40:00  None\n",
      "2016-10-22 06:00:00 [101.3]\n",
      "2016-10-22 06:20:00 [102.50999999999999, 95.82, 85.92, 120.22, 72.48, 73.52, 87.73, 112.27000000000001]\n",
      "2016-10-22 06:40:00 [87.2, 178.57999999999998, 124.64, 82.07]\n",
      "2016-10-22 07:00:00 [97.43, 94.86, 177.19, 101.31, 116.12, 88.46000000000001]\n",
      "2016-10-22 07:20:00 [116.78999999999999, 100.0, 149.88, 143.01, 102.94, 127.64, 200.7, 173.05, 173.89]\n",
      "2016-10-22 07:40:00 [164.79, 171.42000000000002, 124.56, 116.42, 170.9, 137.11]\n",
      "2016-10-22 08:00:00  None\n",
      "2016-10-22 08:20:00  None\n",
      "2016-10-22 08:40:00  None\n",
      "2016-10-22 09:00:00  None\n",
      "2016-10-22 09:20:00  None\n",
      "2016-10-22 09:40:00  None\n",
      "2016-10-23 06:00:00 [89.17, 83.2, 106.55]\n",
      "2016-10-23 06:20:00 [92.86, 94.47, 57.4]\n",
      "2016-10-23 06:40:00 [123.91, 107.28999999999999, 91.58, 143.65]\n",
      "2016-10-23 07:00:00 [97.49000000000001, 91.02, 67.61]\n",
      "2016-10-23 07:20:00 [76.66, 67.77, 78.55, 103.82]\n",
      "2016-10-23 07:40:00 [142.07999999999998, 95.55, 166.18]\n",
      "2016-10-23 08:00:00  None\n",
      "2016-10-23 08:20:00  None\n",
      "2016-10-23 08:40:00  None\n",
      "2016-10-23 09:00:00  None\n",
      "2016-10-23 09:20:00  None\n",
      "2016-10-23 09:40:00  None\n",
      "2016-10-24 06:00:00 [97.93, 117.0, 92.25, 144.01, 78.87]\n",
      "2016-10-24 06:20:00 [257.41999999999996, 162.9]\n",
      "2016-10-24 06:40:00 [142.5, 138.64, 157.57, 124.23]\n",
      "2016-10-24 07:00:00 [188.67000000000002, 161.7, 122.64, 184.09, 190.99, 173.97, 187.5]\n",
      "2016-10-24 07:20:00 [194.76, 169.16, 220.68, 139.56, 177.13, 230.04, 124.65, 209.31]\n",
      "2016-10-24 07:40:00 [191.88, 177.57999999999998, 259.64, 170.19, 93.37, 213.22, 291.38, 379.14, 145.39]\n",
      "2016-10-24 08:00:00  None\n",
      "2016-10-24 08:20:00  None\n",
      "2016-10-24 08:40:00  None\n",
      "2016-10-24 09:00:00  None\n",
      "2016-10-24 09:20:00  None\n",
      "2016-10-24 09:40:00  None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "win_6 = (6-6)*3\n",
    "win_8 = (8-6)*3\n",
    "win_10 = (10-6)*3\n",
    "win_15 = (15-6)*3\n",
    "win_17 = (17-6)*3\n",
    "win_19 = (19-6)*3\n",
    "\n",
    "if task == 'am':\n",
    "    x_range = range(win_6,win_8)\n",
    "    y_range = range(win_8,win_10)\n",
    "    xy_range = range(win_6,win_10)\n",
    "else:\n",
    "    x_range = range(win_15,win_17)\n",
    "    y_range = range(win_17,win_19)\n",
    "    xy_range = range(win_15,win_19)\n",
    "\n",
    "#Read training data\n",
    "path = '../dataSets/training/'\n",
    "file_suffix = '.csv'\n",
    "in_file = 'trajectories(table 5)_training'\n",
    "travel_times = func.read_file_to_travel_times(path, in_file, file_suffix)\n",
    "\n",
    "\n",
    "#Read testing data\n",
    "path = '../dataSets/testing_phase1/'\n",
    "file_suffix = '.csv'\n",
    "in_file = 'trajectories(table 5)_test1'\n",
    "testing_times = func.read_file_to_travel_times(path, in_file, file_suffix)\n",
    "\n",
    "#merge them into one dict\n",
    "routes =  travel_times.keys()\n",
    "for r in routes:\n",
    "    travel_times[r].update(testing_times[r])\n",
    "\n",
    "total_weeks = 6 # ?(train) + 1(valid) + 1(test), take off 10/1~7\n",
    "training_weeks = total_weeks-2\n",
    "testing_weeks = total_weeks-1\n",
    "num_instance = total_weeks*7 # 13 weeks\n",
    "num_window = 13*3 # 6 ~ 19\n",
    "routes = travel_times.keys()\n",
    "print routes\n",
    "window_size = timedelta(minutes=20)\n",
    "window_start = datetime.strptime('2016-09-13 06:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "window_end = datetime.strptime('2016-09-13 19:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "cube_2d = np.zeros((num_instance*num_window))\n",
    "\n",
    "d=0\n",
    "while d < num_instance:\n",
    "    window_scanner = window_start\n",
    "    for t in range(num_window):\n",
    "        if str(window_scanner.date())>='2016-10-18' and str(window_scanner.date())<='2016-10-24' and str(window_scanner.time())>='06:00:00' and str(window_scanner.time())<'10:00:00' :\n",
    "            print str(window_scanner),\n",
    "            try:\n",
    "                print travel_times[target][window_scanner]\n",
    "            except:\n",
    "                print ' None'\n",
    "        try:\n",
    "            cube_2d[d*39+t] = np.mean(travel_times[target][window_scanner])\n",
    "        except:\n",
    "            cube_2d[d*39+t] = 0\n",
    "        window_scanner += window_size\n",
    "    window_start += timedelta(days=1)\n",
    "    d += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (168, 1, 6) (168, 1)\n",
      "Valid data: (42, 1, 6) (42, 1)\n",
      "Test data: (7, 6, 1)\n",
      "Valid non-zero 42\n",
      "Test non-zero: 42\n"
     ]
    }
   ],
   "source": [
    "# Missing value inputation....\n",
    "### to be done\n",
    "# Normalize\n",
    "cube_2d = cube_2d.reshape(-1, 1)\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "normed = scaler.fit_transform(cube_2d)\n",
    "#normed = preprocessing.normalize(cube_2d,axis=0)\n",
    "\n",
    "cube_3d = np.zeros((num_instance,num_window,1))\n",
    "for d in range(num_instance):\n",
    "    for t in range(num_window):\n",
    "        cube_3d[d][t][0] = normed[d*39+t]\n",
    "\n",
    "train = cube_3d[:training_weeks*7,xy_range,:]\n",
    "valid = cube_3d[training_weeks*7:testing_weeks*7,xy_range,:]\n",
    "\n",
    "test = cube_3d[testing_weeks*7:,x_range,:]\n",
    "\n",
    "\n",
    "look_back = 6\n",
    "\n",
    "trX, trY = create_dataset(train, look_back)\n",
    "valX,valY = create_dataset(valid,look_back)\n",
    "\n",
    "\n",
    "trX = np.reshape(trX, (trX.shape[0], 1, trX.shape[1]))\n",
    "valX = np.reshape(valX, (valX.shape[0], 1, valX.shape[1]))\n",
    "\n",
    "print 'Train data:',trX.shape,trY.shape\n",
    "print 'Valid data:',valX.shape,valY.shape\n",
    "print 'Test data:',test.shape\n",
    "print 'Valid non-zero',np.count_nonzero(valY.flatten())\n",
    "print 'Test non-zero:',np.count_nonzero(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.13234244]\n",
      "  [ 0.27049438]\n",
      "  [ 0.44510335]\n",
      "  [ 0.27361342]\n",
      "  [ 0.28858718]\n",
      "  [ 0.39563684]]\n",
      "\n",
      " [[ 0.1704947 ]\n",
      "  [ 0.30787521]\n",
      "  [ 0.25415634]\n",
      "  [ 0.26644677]\n",
      "  [ 0.32717674]\n",
      "  [ 0.41171139]]\n",
      "\n",
      " [[ 0.21533265]\n",
      "  [ 0.19365653]\n",
      "  [ 0.3832396 ]\n",
      "  [ 0.30635331]\n",
      "  [ 0.27415967]\n",
      "  [ 0.38683052]]\n",
      "\n",
      " [[ 0.21363742]\n",
      "  [ 0.21446789]\n",
      "  [ 0.26963248]\n",
      "  [ 0.22663261]\n",
      "  [ 0.36417571]\n",
      "  [ 0.30718421]]\n",
      "\n",
      " [[ 0.19295177]\n",
      "  [ 0.17868277]\n",
      "  [ 0.22499452]\n",
      "  [ 0.21440249]\n",
      "  [ 0.27257056]\n",
      "  [ 0.28101498]]\n",
      "\n",
      " [[ 0.1770915 ]\n",
      "  [ 0.15538363]\n",
      "  [ 0.22210882]\n",
      "  [ 0.16261536]\n",
      "  [ 0.15561855]\n",
      "  [ 0.25638649]]\n",
      "\n",
      " [[ 0.20192698]\n",
      "  [ 0.40030349]\n",
      "  [ 0.26806582]\n",
      "  [ 0.32913093]\n",
      "  [ 0.34887746]\n",
      "  [ 0.40672675]]]\n"
     ]
    }
   ],
   "source": [
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_model(valX,valY,scaler,model):\n",
    "    predY = []\n",
    "    for day in range(7):\n",
    "        val = np.reshape(valX[day*6,:,:],(1,1,6))\n",
    "        for win in range(6):\n",
    "            pred = model.predict(val)\n",
    "            val = np.append(val[0,0,1:],pred)\n",
    "            val = np.reshape(val,(1,1,6))\n",
    "            predY.append(pred)\n",
    "    predY = np.array(predY).reshape(1, -1)\n",
    "    predY = scaler.inverse_transform(predY)\n",
    "    raw_valY = scaler.inverse_transform(valY)\n",
    "    \n",
    "    return my_mape(raw_valY,predY)\n",
    "\n",
    "def record(model,scaler,mape,count,step,task,target,test,LSTM_out,training_weeks,windows):\n",
    "    #record mape\n",
    "    with open('./rnn_record/'+str(training_weeks)+'w_'+target+task+'.txt','w') as record:\n",
    "        record.write('Mape :'+str(mape))\n",
    "        record.write(' Count :'+str(count))\n",
    "        record.write(' Epoch:'+str(step))\n",
    "        record.write(' LSTM out :'+str(LSTM_out)+'\\n')\n",
    "    #make prediction file\n",
    "    with open('./rnn_record/'+str(training_weeks)+'w_'+target+task+'.csv','w') as record:\n",
    "        record.write('\\\"intersection_id\\\",\\\"tollgate_id\\\",\\\"time_window\\\",\\\"avg_travel_time\\\"\\n')\n",
    "        flag = 0\n",
    "        for day in range(7):\n",
    "            ttX = np.array(test[day,:,:])\n",
    "            ttX = np.reshape(ttX,(1,1,6))\n",
    "            for i in range(6):\n",
    "                record.write(target.split('-')[0]+',')\n",
    "                record.write(target.split('-')[1]+',')\n",
    "                record.write(windows[flag]+',')\n",
    "                flag +=1\n",
    "                #predict\n",
    "                pred = model.predict(ttX)\n",
    "                ttX = np.append(ttX[0,0,1:],pred)\n",
    "                ttX = np.reshape(ttX,(1,1,6))\n",
    "                record.write(str(scaler.inverse_transform(pred).flatten()[0])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing route  A-3  LSTM_out  20\n",
      "Step  1  valid score :  0.980834253308\n",
      "Step  2  valid score :  0.884705335692\n",
      "Step  3  valid score :  0.77791949414\n",
      "Step  4  valid score :  0.657707640773\n",
      "Step  5  valid score :  0.522464939694\n",
      "Step  6  valid score :  0.37176492699\n",
      "Step  7  valid score :  0.27332145913\n",
      "Step  8  valid score :  0.264587526981\n",
      "Step  9  valid score :  0.265223611637\n",
      "Step  10  valid score :  0.263592501521\n",
      "Step  11  valid score :  0.26936195574\n",
      "Step  12  valid score :  0.282620649289\n",
      "Step  13  valid score :  0.295680807932\n",
      "Step  14  valid score :  0.295075870987\n",
      "Step  15  valid score :  0.291057841419\n",
      "Step  16  valid score :  0.282986023932\n",
      "Step  17  valid score :  0.282562517719\n",
      "Step  18  valid score :  0.282351648565\n",
      "Step  19  valid score :  0.280595512729\n",
      "Step  20  valid score :  0.288709380063\n",
      "Step  21  valid score :  0.292839731168\n",
      "Step  22  valid score :  0.291822534106\n",
      "Step  23  valid score :  0.280708247801\n",
      "Step  24  valid score :  0.275458493988\n",
      "Step  25  valid score :  0.279704880954\n",
      "Step  26  valid score :  0.287937671568\n",
      "Step  27  valid score :  0.284462730644\n",
      "Step  28  valid score :  0.282084557239\n",
      "Step  29  valid score :  0.281239866205\n",
      "Step  30  valid score :  0.284806531076\n",
      "Step  31  valid score :  0.285994131493\n",
      "Step  32  valid score :  0.286809281187\n",
      "Step  33  valid score :  0.281238124376\n",
      "Step  34  valid score :  0.288624661602\n",
      "Step  35  valid score :  0.291884691172\n",
      "Step  36  valid score :  0.280924882175\n",
      "Step  37  valid score :  0.277519700268\n",
      "Step  38  valid score :  0.281197864906\n",
      "Step  39  valid score :  0.286763922759\n",
      "Step  40  valid score :  0.286758020869\n",
      "Step  41  valid score :  0.285269349828\n",
      "Step  42  valid score :  0.280421520175\n",
      "Step  43  valid score :  0.280613011631\n",
      "Step  44  valid score :  0.278207238487\n",
      "Step  45  valid score :  0.273595861962\n",
      "Step  46  valid score :  0.276279327391\n",
      "Step  47  valid score :  0.279769195118\n",
      "Step  48  valid score :  0.282210397924\n",
      "Step  49  valid score :  0.27581657883\n",
      "Step  50  valid score :  0.273084997769\n",
      "Step  51  valid score :  0.27127449944\n",
      "Step  52  valid score :  0.274927016571\n",
      "Step  53  valid score :  0.271147027623\n",
      "Step  54  valid score :  0.273737517142\n",
      "Step  55  valid score :  0.271032324746\n",
      "Step  56  valid score :  0.271563793454\n",
      "Step  57  valid score :  0.27841505732\n",
      "Step  58  valid score :  0.28448460793\n",
      "Step  59  valid score :  0.276725983455\n",
      "Step  60  valid score :  0.271611766186\n",
      "Step  61  valid score :  0.272820109404\n",
      "Step  62  valid score :  0.267221068177\n",
      "Step  63  valid score :  0.267321713337\n",
      "Step  64  valid score :  0.272847246616\n",
      "Step  65  valid score :  0.274954268971\n",
      "Step  66  valid score :  0.275817436098\n",
      "Step  67  valid score :  0.268144388469\n",
      "Step  68  valid score :  0.271611934965\n",
      "Step  69  valid score :  0.271652564649\n",
      "Step  70  valid score :  0.276521023938\n",
      "Step  71  valid score :  0.270960012732\n",
      "Step  72  valid score :  0.268924346558\n",
      "Step  73  valid score :  0.269979290786\n",
      "Step  74  valid score :  0.27106171589\n",
      "Step  75  valid score :  0.270499030766\n",
      "Step  76  valid score :  0.266952941084\n",
      "Step  77  valid score :  0.278532224528\n",
      "Step  78  valid score :  0.272429570289\n",
      "Step  79  valid score :  0.268815743768\n",
      "Step  80  valid score :  0.268433404042\n",
      "Step  81  valid score :  0.274280388418\n",
      "Step  82  valid score :  0.268622132852\n",
      "Step  83  valid score :  0.26677935622\n",
      "Step  84  valid score :  0.270463976167\n",
      "Step  85  valid score :  0.269632945965\n",
      "Step  86  valid score :  0.272662727024\n",
      "Step  87  valid score :  0.277619346395\n",
      "Step  88  valid score :  0.267416089775\n",
      "Step  89  valid score :  0.264152735739\n",
      "Step  90  valid score :  0.267470583177\n",
      "Step  91  valid score :  0.26625269601\n",
      "Step  92  valid score :  0.270185756697\n",
      "Step  93  valid score :  0.277362548574\n",
      "Step  94  valid score :  0.27173256907\n",
      "Step  95  valid score :  0.264006898834\n",
      "Step  96  valid score :  0.27464972692\n",
      "Step  97  valid score :  0.288607270979\n",
      "Step  98  valid score :  0.267792078488\n",
      "Step  99  valid score :  0.26073502983\n",
      "Step  100  valid score :  0.26757444538\n",
      "Step  101  valid score :  0.272524135401\n",
      "Step  102  valid score :  0.26943813353\n",
      "Step  103  valid score :  0.265542395026\n",
      "Step  104  valid score :  0.263141250253\n",
      "Step  105  valid score :  0.26835003253\n",
      "Step  106  valid score :  0.26625665494\n",
      "Step  107  valid score :  0.263815250025\n",
      "Step  108  valid score :  0.278690326293\n",
      "Step  109  valid score :  0.282798016812\n",
      "Step  110  valid score :  0.262609912939\n",
      "Step  111  valid score :  0.265184396647\n",
      "Step  112  valid score :  0.282553500272\n",
      "Step  113  valid score :  0.273196403321\n",
      "Step  114  valid score :  0.262062118115\n",
      "Step  115  valid score :  0.268156641641\n",
      "Step  116  valid score :  0.271257949953\n",
      "Step  117  valid score :  0.267107521913\n",
      "Step  118  valid score :  0.26497845752\n",
      "Step  119  valid score :  0.26376685005\n",
      "Step  120  valid score :  0.271733394546\n",
      "Step  121  valid score :  0.274167312824\n",
      "Step  122  valid score :  0.268922662558\n",
      "Step  123  valid score :  0.272160967969\n",
      "Step  124  valid score :  0.271701682762\n",
      "Step  125  valid score :  0.26488806979\n",
      "Step  126  valid score :  0.279315322848\n",
      "Step  127  valid score :  0.274761907109\n",
      "Step  128  valid score :  0.268117853903\n",
      "Step  129  valid score :  0.260667974387\n",
      "Step  130  valid score :  0.274255863427\n",
      "Step  131  valid score :  0.271351879173\n",
      "Step  132  valid score :  0.257926780179\n",
      "Step  133  valid score :  0.267679712384\n",
      "Step  134  valid score :  0.275450231074\n",
      "Step  135  valid score :  0.27191525703\n",
      "Step  136  valid score :  0.271568193538\n",
      "Step  137  valid score :  0.277805120691\n",
      "Step  138  valid score :  0.266959415339\n",
      "Step  139  valid score :  0.26585327802\n",
      "Step  140  valid score :  0.264433308855\n",
      "Step  141  valid score :  0.266143115847\n",
      "Step  142  valid score :  0.268324638947\n",
      "Step  143  valid score :  0.267622450937\n",
      "Step  144  valid score :  0.273991096992\n",
      "Step  145  valid score :  0.270594212327\n",
      "Step  146  valid score :  0.270888262679\n",
      "Step  147  valid score :  0.277239847916\n",
      "Step  148  valid score :  0.257917145373\n",
      "Step  149  valid score :  0.26447694298\n",
      "Step  150  valid score :  0.264879504229\n",
      "Step  151  valid score :  0.275296384565\n",
      "Step  152  valid score :  0.2718339494\n",
      "Step  153  valid score :  0.268517087736\n",
      "Step  154  valid score :  0.265121143781\n",
      "Step  155  valid score :  0.270567272444\n",
      "Step  156  valid score :  0.274048750222\n",
      "Step  157  valid score :  0.268917859382\n",
      "Step  158  valid score :  0.272884819501\n",
      "Step  159  valid score :  0.272925326456\n",
      "Step  160  valid score :  0.281244296825\n",
      "Step  161  valid score :  0.268155307271\n",
      "Step  162  valid score :  0.267057399913\n",
      "Step  163  valid score :  0.270697762077\n",
      "Step  164  valid score :  0.282994453243\n",
      "Step  165  valid score :  0.275266927975\n",
      "Step  166  valid score :  0.271506702661\n",
      "Step  167  valid score :  0.287476048466\n",
      "Step  168  valid score :  0.265288087836\n",
      "Step  169  valid score :  0.266056528742\n",
      "Step  170  valid score :  0.3061957343\n",
      "Step  171  valid score :  0.265340243772\n",
      "Step  172  valid score :  0.260293105801\n",
      "Step  173  valid score :  0.268555357004\n",
      "Step  174  valid score :  0.267836202127\n",
      "Step  175  valid score :  0.275982010325\n",
      "Step  176  valid score :  0.275457090777\n",
      "Step  177  valid score :  0.299194747176\n",
      "Step  178  valid score :  0.29785091607\n",
      "Step  179  valid score :  0.258321992781\n",
      "Step  180  valid score :  0.261979327701\n",
      "Step  181  valid score :  0.301215590888\n",
      "Step  182  valid score :  0.258255813241\n",
      "Step  183  valid score :  0.265024271101\n",
      "Step  184  valid score :  0.291763646073\n",
      "Step  185  valid score :  0.286287980987\n",
      "Step  186  valid score :  0.269787398602\n",
      "Step  187  valid score :  0.285852380979\n",
      "Step  188  valid score :  0.28398304759\n",
      "Step  189  valid score :  0.275148896694\n",
      "Step  190  valid score :  0.270035270876\n",
      "Step  191  valid score :  0.27828094668\n",
      "Step  192  valid score :  0.273043252927\n",
      "Step  193  valid score :  0.285959313647\n",
      "Step  194  valid score :  0.272737180051\n",
      "Step  195  valid score :  0.272645098681\n",
      "Step  196  valid score :  0.277273213068\n",
      "Step  197  valid score :  0.269608147352\n",
      "Step  198  valid score :  0.257361285749\n",
      "Step  199  valid score :  0.280759925252\n",
      "Step  200  valid score :  0.316757875021\n",
      "Step  201  valid score :  0.260384907987\n",
      "Step  202  valid score :  0.253513104482\n",
      "Step  203  valid score :  0.309398554551\n",
      "Step  204  valid score :  0.29167745613\n",
      "Step  205  valid score :  0.254616024674\n",
      "Step  206  valid score :  0.275560430304\n",
      "Step  207  valid score :  0.314524737514\n",
      "Step  208  valid score :  0.266127461883\n",
      "Step  209  valid score :  0.26191199001\n",
      "Step  210  valid score :  0.275085251789\n",
      "Step  211  valid score :  0.287481928159\n",
      "Step  212  valid score :  0.279506591798\n",
      "Step  213  valid score :  0.264793959175\n",
      "Step  214  valid score :  0.294083113428\n",
      "Step  215  valid score :  0.291528705913\n",
      "Step  216  valid score :  0.263788195571\n",
      "Step  217  valid score :  0.275200532519\n",
      "Step  218  valid score :  0.277611004439\n",
      "Step  219  valid score :  0.276148490511\n",
      "Step  220  valid score :  0.268501981597\n",
      "Step  221  valid score :  0.295569831491\n",
      "Step  222  valid score :  0.296035819588\n",
      "Step  223  valid score :  0.262063391308\n",
      "Step  224  valid score :  0.280406976021\n",
      "Step  225  valid score :  0.284544473842\n",
      "Step  226  valid score :  0.264295774956\n",
      "Step  227  valid score :  0.284117356158\n",
      "Step  228  valid score :  0.276366222432\n",
      "Step  229  valid score :  0.270607282019\n",
      "Step  230  valid score :  0.289293091392\n",
      "Step  231  valid score :  0.266013045465\n",
      "Step  232  valid score :  0.286165827795\n",
      "Step  233  valid score :  0.302043030211\n",
      "Step  234  valid score :  0.260775294514\n",
      "Step  235  valid score :  0.263032211619\n",
      "Step  236  valid score :  0.297290551001\n",
      "Step  237  valid score :  0.284528358341\n",
      "Step  238  valid score :  0.270888253561\n",
      "Step  239  valid score :  0.283213338624\n",
      "Step  240  valid score :  0.295649432764\n",
      "Step  241  valid score :  0.265724664875\n",
      "Step  242  valid score :  0.25960159929\n",
      "Step  243  valid score :  0.302014236735\n",
      "Step  244  valid score :  0.303203738175\n",
      "Step  245  valid score :  0.26856598464\n",
      "Step  246  valid score :  0.293920829235\n",
      "Step  247  valid score :  0.266829280353\n",
      "Step  248  valid score :  0.286817362713\n",
      "Step  249  valid score :  0.274956244597\n",
      "Step  250  valid score :  0.269387698618\n",
      "Step  251  valid score :  0.305248480764\n",
      "Step  252  valid score :  0.291868466865\n",
      "Step  253  valid score :  0.275112708465\n",
      "Step  254  valid score :  0.302663817624\n",
      "Step  255  valid score :  0.281387835121\n",
      "Step  256  valid score :  0.278310869649\n",
      "Step  257  valid score :  0.319979254661\n",
      "Step  258  valid score :  0.276457025396\n",
      "Step  259  valid score :  0.264184477953\n",
      "Step  260  valid score :  0.302834375033\n",
      "Step  261  valid score :  0.309913805847\n",
      "Step  262  valid score :  0.25760442189\n",
      "Step  263  valid score :  0.282164703165\n",
      "Step  264  valid score :  0.357386806511\n",
      "Step  265  valid score :  0.302878826055\n",
      "Step  266  valid score :  0.253246540642\n",
      "Step  267  valid score :  0.288716432357\n",
      "Step  268  valid score :  0.326075398051\n",
      "Step  269  valid score :  0.268252652147\n",
      "Step  270  valid score :  0.288411054459\n",
      "Step  271  valid score :  0.304987935814\n",
      "Step  272  valid score :  0.288881612287\n",
      "Step  273  valid score :  0.282709546299\n",
      "Step  274  valid score :  0.280640121844\n",
      "Step  275  valid score :  0.296924490276\n",
      "Step  276  valid score :  0.288901928976\n",
      "Step  277  valid score :  0.283347385437\n",
      "Step  278  valid score :  0.298751423159\n",
      "Step  279  valid score :  0.302537288039\n",
      "Step  280  valid score :  0.280491863623\n",
      "Step  281  valid score :  0.294314429551\n",
      "Step  282  valid score :  0.304897743238\n",
      "Step  283  valid score :  0.313968851501\n",
      "Step  284  valid score :  0.298243449932\n",
      "Step  285  valid score :  0.259375655853\n",
      "Step  286  valid score :  0.29838172373\n",
      "Step  287  valid score :  0.282550524053\n",
      "Step  288  valid score :  0.30336110466\n",
      "Step  289  valid score :  0.285724440735\n",
      "Step  290  valid score :  0.285242322182\n",
      "Step  291  valid score :  0.295206031957\n",
      "Step  292  valid score :  0.303261438378\n",
      "Step  293  valid score :  0.281848742396\n",
      "Step  294  valid score :  0.30332047887\n",
      "Step  295  valid score :  0.289770374978\n",
      "Step  296  valid score :  0.268539688829\n",
      "Step  297  valid score :  0.286140874508\n",
      "Step  298  valid score :  0.291257130454\n",
      "Step  299  valid score :  0.279019317378\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4d3da5e557d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2100\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2102\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "diplay = 1\n",
    "step = epoch/diplay\n",
    "LSTM_out = 20\n",
    "best = 0.3\n",
    "\n",
    "sample_w = np.zeros(trY.shape[0])\n",
    "for i in range(len(trY)):\n",
    "    sample_w[i] = 0 if trY[i,0] == 0 else 1/trY[i,0]\n",
    "    \n",
    "\n",
    "# create and fit the LSTM network\n",
    "print \"Doing route \",target,' LSTM_out ',LSTM_out\n",
    "model = Sequential()\n",
    "model.add(GRU(LSTM_out, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "adam = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='mae', optimizer=adam)\n",
    "loss= []\n",
    "for i in range(step):\n",
    "    hist = model.fit(trX, trY, epochs=diplay, verbose=0,sample_weight=sample_w)\n",
    "    mape,count = eval_model(valX,valY,scaler,model)\n",
    "    loss.append(hist.history['loss'])\n",
    "    print 'Step ',(i+1)*diplay,' valid score : ',mape\n",
    "    if best > mape:\n",
    "        best = mape\n",
    "        #record(model,scaler,mape,count,(i+1)*diplay,task,target,test,LSTM_out,training_weeks,windows)\n",
    "print 'Best mape = ',best\n",
    "print model.predict(valX)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
